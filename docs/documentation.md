## Documentation

The Postgres Performance Farm is a system in charge of running benchmarking tests through different Postgres versions. 

Each benchmark aims to run on a newly installed Postgres, without major changes in the default configurations; however, it is possible to change basic parameters. The install does not depend nor interfere with previously existing installations: all directories and sockets are separate by default.

The currently available test is PgBench, also configurable. Furthermore, the script collects basic system information, such as hardware and operating system. There is also execution of collectd, if available.

##### Terminology

The main assumption of the script is that the most relevant results are collecting running tests through different commits within the Postgres repository. Having the same test ran multiple times without any changes in hardware or version does not provide useful information.

Commonly used words are:

* A run is an execution of the script on a single client;
* A benchmark is a single execution of PgBench;
* A given run can have multiple benchmarks done;
* A run should have at least one benchmark.



### Client script

The client script is written in Python3 and takes care of all the client-side part, i. e. downloading and installing Postgres, starting a cluster, executing tests, collecting system information and then shutting down processes and deleting unnecessary folders.

The workflow can be summarized as:

1. Creating (or recreating) all necessary directories;
2. Checking for existing Postgres clones within the Performance Farm folders, and if so, trying to pull for updates;
3. Saving current branch and commit;
4. If there has been an update, or a clone from scratch, Postgres is built using make;
5. A cluster is initialized and started through pg_ctl;
6. System information is collected;
7. PgBench is executed;
8. Cluster is stopped;
9. Data directory is cleaned;
10. Logs are being attached to results and shipped to the server.

##### Files and folders

* perffarm-client.py: takes care of coordinating the setup of benchmarks, and when everything is initialized runs collectors;
* folders.py: global variables related to default folder structure;
* Benchmarks:
  * pgbench.py: takes care of all PgBench related tasks, such as initialization, run of benchmarks and collecting results;
  * runner.py: wrapper calling PgBench functions and saving output in a file
* Collectors:
  * collectd.py: runs collectd to gather system and database statistics;
  * collector.py: combines other collectors and calls them;
  * system.py: contains a collection of Python3 functions from external modules to extract system information such as CPU usage, kernel configuration and memory;
  * postgres.py: mainly a function that connects to Postgres and selects its settings;
* Post example (removed in later versions): 
  * upload.py: takes the output file and sends it to the API;
* Utils: 
  * cluster.py: initalizes, starts and stops a Postgres cluster;
  * build.py: module which takes care of executing a build from source from a git repository;
  * locking.py: ensures locking of files;
  * logging.py: prints nice logging;
  * misc.py: connects to database and returns available RAM.

##### Tuning settings

The Performance Farm comes with some default settings as well as local settings that can be adjusted. Parameters that can be changed are:

* UPDATE, flag to instruct the script to try to pull for new commits at every execution;
* AUTOMATIC_UPLOAD, flag to enable uploading to the server (works only with a valid machine secret);
* GIT_URL, used to specify the repository to pull from;
* BASE_PATH, folder which will be used for Performance Farm files;
* API_URL, current URL of the server (can be changed for local developing);
* MACHINE_SECRET, identifier of the machine on which benchmarks are being run (generated by the server);
* POSTGRES_CONFIG, basic Postgres parameters;
* DATABASE_NAME, database name;
* PGBENCH_CONFIG, parameters to tune PgBench.

##### Folder structure

All folders used within the Performance Farm are children of BASE_PATH, specified in the settings. Specifically, there are:

* BUILD_PATH, containing files generated by configure;
* INSTALL_PATH, installation directory of make;
* BIN_PATH, bin directory of the Postgres installation;
* OUTPUT_PATH, containing all output files generated by PgBench and the script;
* REPOSITORY_PATH, clone of the Postgres remote in which updates are checked;
* DATADIR_PATH, Postgres data directory, getting removed after every execution;
* SOCKET_PATH, folder for sockets to avoid interfering with other Postgres processes;
* LOG_PATH, containing all logs, errors and messages generated by the script.

##### Interpreting results

Output of the script is saved in a JSON format to take advantage of key-value storage, useful for collecting and parsed.

Results are contained in the output folder. There are two main output files: results.json, containing actual results, and results_complete.json, which is the file getting shipped to the server and is equal to the results file plus all the logs attached in sequence. It lacks human readability, therefore the file which should be checked is the first. 

Main fields of the JSON output are:

* pgbench, with a number of nested objects corresponding to the number of runs, each of them with basic information about latency and tps;

* Linux information, divided in:

  * CPU data, along with system times;
  * OS information, its version and architecture;
  * Memory, containing virtual, swap, mounts;
  * Disk usage with I/O;
  * Process information;
  * Compilers (make and gcc);
  * Collectd results;
  * Postgres configuraton;
  * Meta information (date, time, user name).

  

### API

The API is written in Django and Django-REST, using versions compatible with the Postgres website. Its purposes are:

* Defining a database structure for results;
* Receiving, parsing and inserting data;
* Calculating intermediate values;
* Checking for correctness and completeness when database constraints are not sufficient;
* Exposing endpoints to interact with the database.

##### Database structure

The database is being generated by Django and defined through models. Each folder corresponds to a category, and each model file contains several table definitions related to the same object.

Benchmarks: 

* 